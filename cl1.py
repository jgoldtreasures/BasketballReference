from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_scorefrom sklearn.linear_model import LogisticRegressionfrom sklearn.naive_bayes import GaussianNBfrom sklearn.metrics import classification_report, confusion_matrix, precision_score, mean_absolute_error, \    mean_squared_errorfrom sklearn import svmimport numpy as npimport seaborn as snimport matplotlib.pyplot as pltimport mathimport pandas as pddef pretty_print(matrix):    pd.set_option('display.max_rows', None)    pd.set_option('display.max_columns', None)    pd.set_option('display.width', None)    pd.set_option('display.max_colwidth', None)    print(pd.DataFrame(matrix))def heat():    df = pd.read_csv('data/career_stats11.csv')    df = df[df['eligible'] == 1].drop(columns=['hof_prob', 'eligible', 'Player', 'Sixth Man', 'ROY'])    mat = df.corr()    sn.heatmap(mat)    plt.show()    pretty_print(mat)def tce():    df = pd.read_csv('data/career_stats11.csv')    df = df[df['eligible'] == 1].drop(columns=['hof_prob', 'eligible', 'Player', 'Sixth Man', 'ROY'])    stats = ["TRB", "AST", "STL", "BLK", "PTS", "All Star", "MVP", "Def. POY", "All-NBA", "All-Defensive", "leaders",             "NBA Champ", 'Hall of Fame']    for stat in stats:        avg = np.mean(df[stat])        stars = df[df[stat] >= avg]        bums = df[df[stat] < avg]        asg1 = stars['Hall of Fame']        asg2 = bums['Hall of Fame']        # hof = df[df['Hall of Fame'] == 1]        # nonhof = df[df['Hall of Fame'] == 0]        #        # asg1 = hof['All Star']        # asg2 = nonhof['All Star']        #        easg1 = np.mean(asg1)        easg2 = np.mean(asg2)        print(stat, easg2 - easg1)def stratification():    df = pd.read_csv('data/career_stats11.csv')    df = df[df['eligible'] == 1].drop(columns=['hof_prob', 'eligible', 'Player', 'Sixth Man', 'ROY'])    stats = ["TRB", "AST", "STL", "BLK", "PTS"]    for stat in stats:        avg_stat = np.mean(df[stat])        avg_asg = np.mean(df['All Star'])        stat1 = df[df[stat] >= avg_stat]        stat2 = df[df[stat] < avg_stat]        hof1 = stat1[stat1['Hall of Fame'] == 1]        nonhof1 = stat1[stat1['Hall of Fame'] == 0]        one = len(hof1[hof1['All Star'] >= avg_asg])        two = len(hof1[hof1['All Star'] < avg_asg])        three = len(nonhof1[nonhof1['All Star'] >= avg_asg])        four = len(nonhof1[nonhof1['All Star'] < avg_asg])        hof2 = stat2[stat2['Hall of Fame'] == 1]        nonhof2 = stat2[stat2['Hall of Fame'] == 0]        five = len(hof2[hof2['All Star'] >= avg_asg])        six = len(hof2[hof2['All Star'] < avg_asg])        seven = len(nonhof2[nonhof2['All Star'] >= avg_asg])        eight = len(nonhof2[nonhof2['All Star'] < avg_asg])        print(stat, (one / (one + three)) / (two / (two + four)), (five / (five + seven)) / (six / (six + eight)))def ratio():    df = pd.read_csv('data/career_stats11.csv')    df = df[df['eligible'] == 1].drop(columns=['hof_prob', 'eligible', 'Player', 'Sixth Man', 'ROY'])    stats = ["TRB", "AST", "STL", "BLK", "PTS"]    avg_asg = np.mean(df['All Star'])    hof1 = df[df['Hall of Fame'] == 1]    nonhof1 = df[df['Hall of Fame'] == 0]    one = len(hof1[hof1['All Star'] >= avg_asg])    two = len(hof1[hof1['All Star'] < avg_asg])    three = len(nonhof1[nonhof1['All Star'] >= avg_asg])    four = len(nonhof1[nonhof1['All Star'] < avg_asg])    print((one / (one + three)) / (two / (two + four)))def log_reg():    df = pd.read_csv('data/career_stats11.csv')    df = df[df['eligible'] == 1]    df = df[['PTS', 'Hall of Fame']]    n_bins = 5    hof = np.zeros(n_bins)    nonhof = np.zeros(n_bins)    df = df.reset_index(drop=True)    # print(df.loc[10, 'PTS'])    divisor = (max(df['PTS']) - min(df['PTS'])) / n_bins    print(divisor)    bins = [min(df['PTS']) + i * divisor for i in range(n_bins + 1)]    bins[0] = 0    bins[-1] = max(df['PTS']) + 1    print(bins)    df['binned'] = pd.cut(df['PTS'], bins=bins, labels=[i for i in range(n_bins)])    pretty_print(df)    for i in range(len(df)):        if df['Hall of Fame'][i] == 1:            print(df.loc[i, 'binned'])            hof[df.loc[i, 'binned']] += 1        else:            print(df.loc[i, 'binned'])            nonhof[df.loc[i, 'binned']] += 1def histo():    df = pd.read_csv('data/career_stats11.csv')    df = df[df['eligible'] == 1]    df = df[['PTS', 'Hall of Fame']]    n_bins = 5    hof = np.zeros(n_bins)    nonhof = np.zeros(n_bins)    df = df.reset_index(drop=True)    # print(df.loc[10, 'PTS'])    divisor = (max(df['PTS']) - min(df['PTS'])) / n_bins    print(divisor)    bins = [min(df['PTS']) + i * divisor for i in range(n_bins + 1)]    bins[0] = 0    bins[-1] = max(df['PTS']) + 1    print(bins)    df['binned'] = pd.cut(df['PTS'], bins=bins, labels=[i for i in range(n_bins)])    pretty_print(df)    for i in range(len(df)):        if df['Hall of Fame'][i] == 1:            print(df.loc[i, 'binned'])            hof[df.loc[i, 'binned']] += 1        else:            print(df.loc[i, 'binned'])            nonhof[df.loc[i, 'binned']] += 1    print(df)    print(hof)    print(nonhof)    perc = hof / (hof + nonhof)    plt.bar([i for i in range(n_bins)], perc)    plt.show()def pltxvsy():    df = pd.read_csv('data/career_stats11.csv')    df = df[df['eligible'] == 1]    # df = df[['All Star', 'All-NBA']]    plt.scatter(df['All Star'], df['All-NBA'])    plt.show()    plt.scatter(df['All Star'], df['PTS'])    plt.show()def log_reg1():    df = pd.read_csv('data/career_stats11.csv')    training = df[df['eligible'] == 1]    model = LogisticRegression().fit(training[['All Star', "TRB", "AST", "STL", "BLK", "PTS"]], training['Hall of Fame'])    print(model.coef_[0], model.intercept_[0])    # X = logit(model.coef_, model.intercept_, 1000, max(training['All Star']))    #    # plt.plot(X[:, 0], X[:, 1])    # plt.scatter(training[['All Star']], training['Hall of Fame'], color='red')    # plt.show()def squash():    df = pd.read_csv('data/career_stats10.csv')    df2 = pd.DataFrame.copy(df)    # df2['leaders'] = df[]    columns = ['Scoring Champ', 'AST Champ', 'TRB Champ', 'STL Champ', 'BLK Champ']    df2['leaders'] = sum([df2[i] for i in columns])    df2 = df2.drop(columns, axis=1)    df2.to_csv('data/career_stats11.csv', index=False)def logit(k, x_0, n, max):    X = np.zeros((n, 2))    for i in range(n):        x = max * i / n        X[i, :] = x, 1/(1 + math.exp(-1 * (k * x + x_0)))    return Xdef main():    # heat()    # tce()    # stratification()    # ratio()    # squash(ha)    # prediction()    # histo()    # pltxvsy()    log_reg1()main()